Page 23

Humans are good at some NP hard problems that we were evolved to do...

**"A central point of this document is that general intelligence is not a binary proprety"** and we don't have a not anthropecentric way of measuring it.

cannot set intelligence as an absolute goal, need to define the kinds of tasks and skills
claim: we should work on human like systems and benchmark them like humans are benmarked

**No free lunch theorm**
control for priors and expeirence, so we need to understand human priors

current ai systems aren't smart, the use experience to simulate generality

intelligence equals generality

proposed test is very similar to RL envs..

complexity of everything contained in binary strings, programs run on universal turing machines and take strings in/out

complexity of the program is "machinesindependent to a constant"

(35)
cycle involves "training" and "evaluation", and the generalization difficulty is the difference in the evaluation task and the training task... aka if the training and evaluation metrics are the same, then difficlut is zero.

complexity is correlated with generalizability

also have to include the developers knowledge computationally somehow... this is all so abstract with the binary strings..

a bunch of math to formally define the intelligence of a system

**"Intelligence is the rate at which an learner turns its experience and prors into new skills... generalization"**

skill is not intelligence, skill skill is not high intelligence

intelligence is measured by prior-efficency and experience-efficiency, although other metrics could be considered (computation, time, energy, risk)

everyone likes optimization problems

Seperation of intelligence and skill... does our brain do that? How? Why should the line be drawn there... should priors be a different thing as well? (philisophical)

end II.2.3b (pg 43)
